{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cont1</th>\n",
       "      <th>cont2</th>\n",
       "      <th>cont3</th>\n",
       "      <th>cont4</th>\n",
       "      <th>cont5</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>cont14</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>131822.00000</td>\n",
       "      <td>131822.000000</td>\n",
       "      <td>131822.000000</td>\n",
       "      <td>131822.000000</td>\n",
       "      <td>131822.000000</td>\n",
       "      <td>131822.000000</td>\n",
       "      <td>131822.000000</td>\n",
       "      <td>131822.000000</td>\n",
       "      <td>131822.000000</td>\n",
       "      <td>131822.00000</td>\n",
       "      <td>131822.000000</td>\n",
       "      <td>131822.000000</td>\n",
       "      <td>131822.000000</td>\n",
       "      <td>131822.000000</td>\n",
       "      <td>131822.000000</td>\n",
       "      <td>131822.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>65910.50000</td>\n",
       "      <td>0.493342</td>\n",
       "      <td>0.507205</td>\n",
       "      <td>0.499348</td>\n",
       "      <td>0.491129</td>\n",
       "      <td>0.486648</td>\n",
       "      <td>0.490494</td>\n",
       "      <td>0.485201</td>\n",
       "      <td>0.486195</td>\n",
       "      <td>0.48512</td>\n",
       "      <td>0.497715</td>\n",
       "      <td>0.493509</td>\n",
       "      <td>0.493151</td>\n",
       "      <td>0.492624</td>\n",
       "      <td>0.495778</td>\n",
       "      <td>3039.973828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>38053.87793</td>\n",
       "      <td>0.187592</td>\n",
       "      <td>0.207240</td>\n",
       "      <td>0.202093</td>\n",
       "      <td>0.211094</td>\n",
       "      <td>0.208703</td>\n",
       "      <td>0.205043</td>\n",
       "      <td>0.178781</td>\n",
       "      <td>0.199229</td>\n",
       "      <td>0.18146</td>\n",
       "      <td>0.185664</td>\n",
       "      <td>0.209614</td>\n",
       "      <td>0.209308</td>\n",
       "      <td>0.212643</td>\n",
       "      <td>0.222450</td>\n",
       "      <td>2913.957535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.001149</td>\n",
       "      <td>0.002634</td>\n",
       "      <td>0.176921</td>\n",
       "      <td>0.281143</td>\n",
       "      <td>0.012683</td>\n",
       "      <td>0.069503</td>\n",
       "      <td>0.236880</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035321</td>\n",
       "      <td>0.036232</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.180268</td>\n",
       "      <td>5.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>32955.25000</td>\n",
       "      <td>0.344779</td>\n",
       "      <td>0.358319</td>\n",
       "      <td>0.336963</td>\n",
       "      <td>0.327354</td>\n",
       "      <td>0.281143</td>\n",
       "      <td>0.335056</td>\n",
       "      <td>0.350378</td>\n",
       "      <td>0.312800</td>\n",
       "      <td>0.35897</td>\n",
       "      <td>0.364580</td>\n",
       "      <td>0.310961</td>\n",
       "      <td>0.312482</td>\n",
       "      <td>0.315758</td>\n",
       "      <td>0.294752</td>\n",
       "      <td>1204.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>65910.50000</td>\n",
       "      <td>0.475784</td>\n",
       "      <td>0.555782</td>\n",
       "      <td>0.527991</td>\n",
       "      <td>0.452887</td>\n",
       "      <td>0.422268</td>\n",
       "      <td>0.439786</td>\n",
       "      <td>0.438480</td>\n",
       "      <td>0.441060</td>\n",
       "      <td>0.43731</td>\n",
       "      <td>0.461190</td>\n",
       "      <td>0.457203</td>\n",
       "      <td>0.462286</td>\n",
       "      <td>0.363547</td>\n",
       "      <td>0.407411</td>\n",
       "      <td>2116.585000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>98865.75000</td>\n",
       "      <td>0.623912</td>\n",
       "      <td>0.681761</td>\n",
       "      <td>0.634224</td>\n",
       "      <td>0.652072</td>\n",
       "      <td>0.635304</td>\n",
       "      <td>0.653958</td>\n",
       "      <td>0.591284</td>\n",
       "      <td>0.623580</td>\n",
       "      <td>0.55855</td>\n",
       "      <td>0.614590</td>\n",
       "      <td>0.678924</td>\n",
       "      <td>0.675759</td>\n",
       "      <td>0.689974</td>\n",
       "      <td>0.724610</td>\n",
       "      <td>3865.105000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>131821.00000</td>\n",
       "      <td>0.984975</td>\n",
       "      <td>0.862654</td>\n",
       "      <td>0.944251</td>\n",
       "      <td>0.952482</td>\n",
       "      <td>0.983674</td>\n",
       "      <td>0.997162</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980200</td>\n",
       "      <td>0.99540</td>\n",
       "      <td>0.994980</td>\n",
       "      <td>0.998742</td>\n",
       "      <td>0.998484</td>\n",
       "      <td>0.988494</td>\n",
       "      <td>0.844844</td>\n",
       "      <td>121012.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id          cont1          cont2          cont3  \\\n",
       "count  131822.00000  131822.000000  131822.000000  131822.000000   \n",
       "mean    65910.50000       0.493342       0.507205       0.499348   \n",
       "std     38053.87793       0.187592       0.207240       0.202093   \n",
       "min         0.00000       0.000016       0.001149       0.002634   \n",
       "25%     32955.25000       0.344779       0.358319       0.336963   \n",
       "50%     65910.50000       0.475784       0.555782       0.527991   \n",
       "75%     98865.75000       0.623912       0.681761       0.634224   \n",
       "max    131821.00000       0.984975       0.862654       0.944251   \n",
       "\n",
       "               cont4          cont5          cont6          cont7  \\\n",
       "count  131822.000000  131822.000000  131822.000000  131822.000000   \n",
       "mean        0.491129       0.486648       0.490494       0.485201   \n",
       "std         0.211094       0.208703       0.205043       0.178781   \n",
       "min         0.176921       0.281143       0.012683       0.069503   \n",
       "25%         0.327354       0.281143       0.335056       0.350378   \n",
       "50%         0.452887       0.422268       0.439786       0.438480   \n",
       "75%         0.652072       0.635304       0.653958       0.591284   \n",
       "max         0.952482       0.983674       0.997162       1.000000   \n",
       "\n",
       "               cont8         cont9         cont10         cont11  \\\n",
       "count  131822.000000  131822.00000  131822.000000  131822.000000   \n",
       "mean        0.486195       0.48512       0.497715       0.493509   \n",
       "std         0.199229       0.18146       0.185664       0.209614   \n",
       "min         0.236880       0.00008       0.000000       0.035321   \n",
       "25%         0.312800       0.35897       0.364580       0.310961   \n",
       "50%         0.441060       0.43731       0.461190       0.457203   \n",
       "75%         0.623580       0.55855       0.614590       0.678924   \n",
       "max         0.980200       0.99540       0.994980       0.998742   \n",
       "\n",
       "              cont12         cont13         cont14           loss  \n",
       "count  131822.000000  131822.000000  131822.000000  131822.000000  \n",
       "mean        0.493151       0.492624       0.495778    3039.973828  \n",
       "std         0.209308       0.212643       0.222450    2913.957535  \n",
       "min         0.036232       0.000228       0.180268       5.250000  \n",
       "25%         0.312482       0.315758       0.294752    1204.890000  \n",
       "50%         0.462286       0.363547       0.407411    2116.585000  \n",
       "75%         0.675759       0.689974       0.724610    3865.105000  \n",
       "max         0.998484       0.988494       0.844844  121012.250000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "data_train = []\n",
    "train = pd.read_csv(\"../data/pml_train.csv\")\n",
    "test = pd.read_csv(\"../data/pml_test_features.csv\")\n",
    "train.describe(include = [np.number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>cat10</th>\n",
       "      <th>...</th>\n",
       "      <th>cat107</th>\n",
       "      <th>cat108</th>\n",
       "      <th>cat109</th>\n",
       "      <th>cat110</th>\n",
       "      <th>cat111</th>\n",
       "      <th>cat112</th>\n",
       "      <th>cat113</th>\n",
       "      <th>cat114</th>\n",
       "      <th>cat115</th>\n",
       "      <th>cat116</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>131822</td>\n",
       "      <td>131822</td>\n",
       "      <td>131822</td>\n",
       "      <td>131822</td>\n",
       "      <td>131822</td>\n",
       "      <td>131822</td>\n",
       "      <td>131822</td>\n",
       "      <td>131822</td>\n",
       "      <td>131822</td>\n",
       "      <td>131822</td>\n",
       "      <td>...</td>\n",
       "      <td>131822</td>\n",
       "      <td>131822</td>\n",
       "      <td>131822</td>\n",
       "      <td>131822</td>\n",
       "      <td>131822</td>\n",
       "      <td>131822</td>\n",
       "      <td>131822</td>\n",
       "      <td>131822</td>\n",
       "      <td>131822</td>\n",
       "      <td>131822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>78</td>\n",
       "      <td>125</td>\n",
       "      <td>16</td>\n",
       "      <td>51</td>\n",
       "      <td>60</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>B</td>\n",
       "      <td>BI</td>\n",
       "      <td>CL</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>BM</td>\n",
       "      <td>A</td>\n",
       "      <td>K</td>\n",
       "      <td>HK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>99116</td>\n",
       "      <td>74609</td>\n",
       "      <td>124588</td>\n",
       "      <td>90018</td>\n",
       "      <td>86487</td>\n",
       "      <td>92249</td>\n",
       "      <td>128634</td>\n",
       "      <td>124065</td>\n",
       "      <td>79091</td>\n",
       "      <td>112104</td>\n",
       "      <td>...</td>\n",
       "      <td>33177</td>\n",
       "      <td>45793</td>\n",
       "      <td>107139</td>\n",
       "      <td>17813</td>\n",
       "      <td>90018</td>\n",
       "      <td>17589</td>\n",
       "      <td>18233</td>\n",
       "      <td>92249</td>\n",
       "      <td>30786</td>\n",
       "      <td>14767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          cat1    cat2    cat3    cat4    cat5    cat6    cat7    cat8  \\\n",
       "count   131822  131822  131822  131822  131822  131822  131822  131822   \n",
       "unique       2       2       2       2       2       2       2       2   \n",
       "top          A       A       A       A       A       A       A       A   \n",
       "freq     99116   74609  124588   90018   86487   92249  128634  124065   \n",
       "\n",
       "          cat9   cat10   ...    cat107  cat108  cat109  cat110  cat111  \\\n",
       "count   131822  131822   ...    131822  131822  131822  131822  131822   \n",
       "unique       2       2   ...        19      11      78     125      16   \n",
       "top          A       A   ...         F       B      BI      CL       A   \n",
       "freq     79091  112104   ...     33177   45793  107139   17813   90018   \n",
       "\n",
       "        cat112  cat113  cat114  cat115  cat116  \n",
       "count   131822  131822  131822  131822  131822  \n",
       "unique      51      60      18      23     307  \n",
       "top          E      BM       A       K      HK  \n",
       "freq     17589   18233   92249   30786   14767  \n",
       "\n",
       "[4 rows x 116 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe(include = ['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['A' 'A' 'A' ..., '0.481306' '0.756454' '0.344502']\n",
      " ['B' 'A' 'A' ..., '0.458493' '0.30435' '0.470455']\n",
      " ['A' 'A' 'A' ..., '0.352251' '0.339244' '0.283969']\n",
      " ..., \n",
      " ['A' 'B' 'A' ..., '0.682413' '0.633362' '0.680872']\n",
      " ['A' 'A' 'A' ..., '0.413475' '0.666708' '0.771625']\n",
      " ['A' 'B' 'A' ..., '0.523266' '0.318646' '0.521525']]\n",
      "['2152.8' '1019.89' '4477.83' ..., '5675.63' '3926.72' '2609.21']\n",
      "[['B' 'A' 'A' ..., '0.331363' '0.359249' '0.312885']\n",
      " ['A' 'A' 'A' ..., '0.832976' '0.832658' '0.81255']\n",
      " ['A' 'B' 'A' ..., '0.933174' '0.926619' '0.848129']\n",
      " ..., \n",
      " ['A' 'A' 'A' ..., '0.569745' '0.55738' '0.282249']\n",
      " ['B' 'B' 'A' ..., '0.301022' '0.305148' '0.559714']\n",
      " ['A' 'B' 'A' ..., '0.24541' '0.241676' '0.298734']]\n"
     ]
    }
   ],
   "source": [
    "data_train = []\n",
    "with open('../data/pml_train.csv', 'rb') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        data_train.append(row) \n",
    "\n",
    "data_train = np.array(data_train)\n",
    "\n",
    "\n",
    "data_test = []\n",
    "with open('../data/pml_test_features.csv', 'rb') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        data_test.append(row) \n",
    "data_test = np.array(data_test)\n",
    "\n",
    "\n",
    "Xtrain = data_train[1:,1:-1]\n",
    "ytrain = data_train[1:,-1]\n",
    "Xtest = data_test[1:,1:-1]\n",
    "\n",
    "print Xtrain\n",
    "print ytrain\n",
    "print Xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols_to_drop = ['id','cont1','cont2','cont3','cont4','cont5','cont6','cont7','cont8','cont9','cont10','cont11','cont12','cont13','cont14','loss']\n",
    "cols_num = ['id','cont1','cont2','cont3','cont4','cont5','cont6','cont7','cont8','cont9','cont10','cont11','cont12','cont13','cont14']\n",
    "\n",
    "x_num_train = train[cols_num].as_matrix()\n",
    "x_num_test = test[cols_num].as_matrix()\n",
    "y_train = train['loss'].as_matrix()\n",
    "cat_train = train.drop(cols_to_drop, axis = 1)\n",
    "cat_test = test.drop(cols_num, axis = 1)\n",
    "x_cat_train = cat_train.T.to_dict().values()\n",
    "x_cat_test = cat_test.T.to_dict().values()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131821 1111 56495\n",
      "(56495, 1065)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer as DV\n",
    "\n",
    "vectorizer = DV(sparse = False)\n",
    "vec_x_cat_train = vectorizer.fit_transform(x_cat_train)\n",
    "vec_x_cat_test = vectorizer.fit_transform(x_cat_test)\n",
    "x_train = np.hstack((x_num_train,vec_x_cat_train))\n",
    "x_test = np.hstack((x_num_test,vec_x_cat_test))\n",
    "Xtrain = x_train[1:,1:]\n",
    "Xtest = x_test[1:,1:]\n",
    "ytrain = y_train[1:]\n",
    "#ytest = y_train[100000:102000]\n",
    "sampleNum,featureNum = Xtrain.shape\n",
    "testNum = len(Xtest)\n",
    "print sampleNum,featureNum,testNum\n",
    "print (Xtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56495, 1065)\n"
     ]
    }
   ],
   "source": [
    "Xtrain=np.array(Xtrain,dtype=float)\n",
    "ytrain=np.array(ytrain,dtype=float)\n",
    "Xtest=np.array(Xtest,dtype=float)\n",
    "#ytest = np.array(ytest,dtype=float)\n",
    "print(Xtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish training\n",
      "('training mse:', 3124768.1343001192)\n",
      "('training mae:', 1130.3193391171828)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (56495,1065) and (1111,200) not aligned: 1065 (dim 1) != 1111 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-10594f45967d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m######### Begin test ###########\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0my_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0mnum_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mnum_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/playpen/hTan/.cat/local/lib/python2.7/site-packages/sklearn/neural_network/multilayer_perceptron.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \"\"\"\n\u001b[1;32m   1256\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"coefs_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1257\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1258\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/playpen/hTan/.cat/local/lib/python2.7/site-packages/sklearn/neural_network/multilayer_perceptron.pyc\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    674\u001b[0m                                          layer_units[i + 1])))\n\u001b[1;32m    675\u001b[0m         \u001b[0;31m# forward propagate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/playpen/hTan/.cat/local/lib/python2.7/site-packages/sklearn/neural_network/multilayer_perceptron.pyc\u001b[0m in \u001b[0;36m_forward_pass\u001b[0;34m(self, activations)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers_\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             activations[i + 1] = safe_sparse_dot(activations[i],\n\u001b[0;32m--> 104\u001b[0;31m                                                  self.coefs_[i])\n\u001b[0m\u001b[1;32m    105\u001b[0m             \u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercepts_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/playpen/hTan/.cat/local/lib/python2.7/site-packages/sklearn/utils/extmath.pyc\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfast_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (56495,1065) and (1111,200) not aligned: 1065 (dim 1) != 1111 (dim 0)"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "model = SVR(C=1e3)\n",
    "modelName = \"SVM\"\n",
    "\"\"\"\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "model = MLPRegressor(hidden_layer_sizes = (200,) )\n",
    "\"\"\"\n",
    "\n",
    "model.fit(Xtrain[:10000],ytrain[:10000])\n",
    "print(\"finish training\")\n",
    "# mean absolute loss (MAE) is used in the competition\n",
    "\n",
    "y_ = model.predict(Xtrain[:10000])\n",
    "print(\"finish prediction\")\n",
    "mse = ( (ytrain[:10000] - y_) ** 2).mean()\n",
    "print('training mse:', mse)\n",
    "\n",
    "mae = ( np.absolute(ytrain[:10000] - y_[:10000])).mean()\n",
    "print('training mae:', mae)\n",
    "\n",
    "\n",
    "#y_ = model.predict(Xtest)\n",
    "y_ = model.predict(Xtrain[100000:102000])\n",
    "\n",
    "num_test = len(y_) \n",
    "print num_test\n",
    "mae = (np.absolute(ytrain[100000:102000] - y_)).mean()\n",
    "print mae\n",
    "\n",
    "\"\"\"\n",
    "model.fit(Xtrain,ytrain)\n",
    "print(\"finish training\")\n",
    "# mean absolute loss (MAE) is used in the competition\n",
    "\n",
    "y_ = model.predict(Xtrain)\n",
    "mse = ( (ytrain - y_) ** 2).mean()\n",
    "print('training mse:', mse)\n",
    "\n",
    "mae = ( np.absolute(ytrain - y_)).mean()\n",
    "print('training mae:', mae)\n",
    "\n",
    "######### Begin test ###########\n",
    "y_ = model.predict(Xtest)\n",
    "num_test = len(y_) \n",
    "print num_test\n",
    "\n",
    "\n",
    "\n",
    "f = open('../data/result-nn-default.csv', 'wb')\n",
    "try:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow( ('id', 'loss') )\n",
    "    for i in range(num_test):\n",
    "        writer.writerow( ( Xtest[i+1, 0], y_[i] ) )\n",
    "finally:\n",
    "    f.close()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
